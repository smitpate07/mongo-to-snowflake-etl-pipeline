# ğŸ“Š MongoDB â†’ Snowflake ETL Pipeline  

## ğŸ“Œ Problem Statement  
Many organizations store **semi-structured JSON data** in **MongoDB**.  
While MongoDB is great for application storage, analysts need this data in **Snowflake** for BI, reporting, and analytics.  

The challenges are:  
- MongoDB documents often contain **nested arrays** (e.g., exam/quiz/homework scores).  
- Snowflake requires **structured, tabular data** for querying.  
- We must ensure **data quality** (row counts match before loading into production).  

---

## ğŸ¯ Solution  
This project implements a **Python-based ETL pipeline** to move data from **MongoDB** to **Snowflake** in a reliable and structured way.  

**Pipeline Workflow:**  
1. Extract documents from MongoDB  
2. Load raw JSON into a **Snowflake staging table**  
3. Validate row counts between MongoDB and Snowflake staging  
4. If counts match, transform and load the data into a ** Persistent Staging Area** table. Below is high level overview

![Pipeline Flow](img/high_level.png)


## Demo: 

https://github.com/user-attachments/assets/d1a4d26c-e532-4dd6-a69c-0840b0fbf542


---

## ğŸ—ï¸ Data Example  

### MongoDB Document  
```json
{
  "_id": "56d5f7eb604eb380b0d8d8ce",
  "student_id": 0,
  "class_id": 339,
  "scores": [
    {"type": "exam", "score": 78.40},
    {"type": "quiz", "score": 73.36},
    {"type": "homework", "score": 46.98}
  ]
}
```

### Final PSA Table in Snowflake

| ID                        | STUDENT_ID | CLASS_ID | TYPE     | SCORE  |
|----------------------------|-----------|----------|---------|--------|
| 56d5f7eb604eb380b0d8d8ce  | 0         | 339      | exam    | 78.40  |
| 56d5f7eb604eb380b0d8d8ce  | 0         | 339      | quiz    | 73.36  |
| 56d5f7eb604eb380b0d8d8ce  | 0         | 339      | homework| 46.98  |


### Project Structure 

    mongo_to_snowflake/
    â”‚â”€â”€ .env                 # Environment variables (not committed to GitHub)
    â”‚â”€â”€ config.py            # Load secrets and settings from .env
    â”‚â”€â”€ mongo_utils.py       # MongoDB connection & extraction logic
    â”‚â”€â”€ snowflake_utils.py   # Snowflake connection & load logic
    â”‚â”€â”€ pipeline.py          # Orchestrates ETL flow
    â”‚â”€â”€ main.py              # Entry point for running pipeline
    â”‚â”€â”€ requirements.txt     # Python dependencies
    â”‚â”€â”€ README.md            # Project documentation


### The pipeline will:

âœ… Connect to MongoDB

âœ… Extract documents

âœ… Load raw data into Snowflake staging

âœ… Validate row counts

âœ… If counts match â†’ transform & load into PSA schema



### Features

âœ… Modular Python design (easy to extend & maintain)

âœ… Secrets managed via .env (secure & configurable)

âœ… Data validation with row count check

âœ… Automatic flattening of nested arrays into structured rows

### Results

STG Results

![STG](img/stg_results.png)

PSA Results

![PSA](img/psa_results.png)

### ğŸ“Š Future Enhancements

Add logging to file.

Add Airflow/Dagster for orchestration & scheduling.

Support multiple MongoDB collections â†’ Snowflake tables.
